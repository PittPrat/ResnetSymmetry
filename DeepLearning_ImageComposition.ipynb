{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEP2LLfsPr21D910088G40",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PittPrat/ResnetSymmetry/blob/master/DeepLearning_ImageComposition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfnxToBWcoLX"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from scipy.fftpack import fft2, fftshift\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set dataset path (All images in one folder)\n",
        "dataset_path = \"/content/drive/MyDrive/symmetry_dataset/\"\n",
        "image_paths = [os.path.join(dataset_path, f) for f in os.listdir(dataset_path) if f.endswith(\".jpg\")]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Parameters\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Load and preprocess images\n",
        "images = np.array([preprocess_image(img) for img in image_paths])\n",
        "print(f\"Loaded {len(images)} images.\")\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "    image = cv2.imread(image_path)\n",
        "    if image is None:\n",
        "        print(f\"Warning: Unable to read image {image_path}\")\n",
        "        return None\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Ensure correct color format\n",
        "    image = cv2.resize(image, (224, 224))\n",
        "    image = image.astype(\"float32\") / 255.0\n",
        "    return np.expand_dims(image, axis=0)\n",
        "\n",
        "def compute_fourier_features(image_path):\n",
        "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
        "    if image is None:\n",
        "        print(f\"Warning: Unable to process Fourier features for {image_path}\")\n",
        "        return None\n",
        "    f_transform = np.fft.fft2(image)\n",
        "    f_shift = np.fft.fftshift(f_transform)\n",
        "    magnitude_spectrum = np.log1p(np.abs(f_shift))\n",
        "    magnitude_spectrum_resized = cv2.resize(magnitude_spectrum, (224, 224))\n",
        "    return magnitude_spectrum_resized.flatten()"
      ],
      "metadata": {
        "id": "CaUtbt8WcwFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save Fourier Features for Future Use\n",
        "fourier_features_path = \"/content/drive/MyDrive/Output/fourier_features.pkl\"\n",
        "features_flattened = fourier_features.reshape(fourier_features.shape[0], -1)\n",
        "with open(fourier_features_path, \"wb\") as f:\n",
        "    pickle.dump(features_flattened, f)\n",
        "print(f\"Fourier features saved at: {fourier_features_path}\")\n"
      ],
      "metadata": {
        "id": "7UbEJ1ZVcxbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load saved fourier features\n",
        "import pickle\n",
        "fourier_features_path = \"/content/drive/MyDrive/Output/fourier_features.pkl\"\n",
        "# Load Fourier Features (if needed)\n",
        "def load_fourier_features(file_path):\n",
        "    with open(file_path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\n",
        "fourier_features = load_fourier_features(fourier_features_path)\n",
        "print(\"Loaded Fourier features shape:\", fourier_features.shape)"
      ],
      "metadata": {
        "id": "BfP6-bi7c1mC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "features_flattened = fourier_features.reshape(fourier_features.shape[0], -1)\n",
        "\n",
        "# Apply K-Means Clustering\n",
        "num_clusters = 2  # Symmetric & Asymmetric\n",
        "kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "kmeans_labels = kmeans.fit_predict(features_flattened)\n",
        "\n",
        "# Visualizing Clusters with PCA\n",
        "pca = PCA(n_components=2)\n",
        "pca_features = pca.fit_transform(features_flattened)\n",
        "plt.scatter(pca_features[:, 0], pca_features[:, 1], c=kmeans_labels, cmap=\"viridis\")\n",
        "plt.xlabel(\"PCA 1\")\n",
        "plt.ylabel(\"PCA 2\")\n",
        "plt.title(\"Image Clusters based on Fourier Features\")\n",
        "plt.colorbar()\n",
        "plt.show()\n",
        "\n",
        "# Create labeled directories\n",
        "os.makedirs(\"/content/drive/MyDrive/Output/Symmetric\", exist_ok=True)\n",
        "os.makedirs(\"/content/drive/MyDrive/Output/Asymmetric\", exist_ok=True)\n",
        "\n",
        "# Move images into respective clusters\n",
        "for img_path, label in zip(image_paths, kmeans_labels):\n",
        "    label_folder = \"Symmetric\" if label == 0 else \"Asymmetric\"\n",
        "    os.rename(img_path, f\"/content/drive/MyDrive/Output/{label_folder}/{os.path.basename(img_path)}\")\n",
        "\n",
        "# Load Auto-Labeled Data\n",
        "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
        "train_data = datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Output/\",\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"training\"\n",
        ")\n",
        "val_data = datagen.flow_from_directory(\n",
        "    \"/content/drive/MyDrive/Output/\",\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"binary\",\n",
        "    subset=\"validation\"\n",
        ")\n",
        "\n",
        "# Load Pretrained ResNet50\n",
        "base_model = ResNet50(weights=\"imagenet\", include_top=False, pooling=\"avg\", input_shape=(224, 224, 3))\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Define Model with Custom Classification Head\n",
        "model = Sequential([\n",
        "    base_model,\n",
        "    Dense(128, activation=\"relu\"),\n",
        "    Dropout(0.5),\n",
        "    Dense(1, activation=\"sigmoid\")  # Binary classification\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "# Train Model\n",
        "history = model.fit(\n",
        "    train_data,\n",
        "    validation_data=val_data,\n",
        "    epochs=10,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate Model\n",
        "loss, accuracy = model.evaluate(val_data)\n",
        "print(f\"Validation Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Plot Training Results\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.legend()\n",
        "plt.title(\"Model Accuracy\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'], label='Train Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.legend()\n",
        "plt.title(\"Model Loss\")\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Save Model for Download\n",
        "model_save_path = \"/content/drive/MyDrive/Output/symmetry_classification_model.h5\"\n",
        "model.save(model_save_path)\n",
        "print(f\"Model saved at: {model_save_path}\")\n"
      ],
      "metadata": {
        "id": "nz7U4f7Yc_At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Predict on New Image\n",
        "def predict_image(image_path):\n",
        "    img = preprocess_image(image_path)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    prediction = model.predict(img)\n",
        "    label = \"Symmetric\" if prediction >= 0.5 else \"Asymmetric\"\n",
        "    print(f\"Prediction for {image_path}: {label}\")\n",
        "\n",
        "# Example Usage\n",
        "sample_image = \"/content/drive/MyDrive/Test Resnet/TestOne.jpg\"\n",
        "predict_image(sample_image)\n"
      ],
      "metadata": {
        "id": "BsOxZKXudBHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define Test Data Path\n",
        "test_data_path = \"/content/drive/MyDrive/Test data/\"\n",
        "\n",
        "# Create an ImageDataGenerator for test set (No Augmentation, Just Rescaling)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_data = test_datagen.flow_from_directory(\n",
        "    test_data_path,\n",
        "    target_size=(224, 224),\n",
        "    batch_size=32,\n",
        "    class_mode=\"binary\",\n",
        "    shuffle=False  # No shuffling for test evaluation\n",
        ")\n",
        "\n",
        "# Print Number of Test Images\n",
        "print(f\"Loaded {test_data.samples} test images.\")\n"
      ],
      "metadata": {
        "id": "0yNR1gLQdFDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate model on test dataset\n",
        "test_loss, test_accuracy = model.evaluate(test_data)\n",
        "print(f\"Final Test Accuracy: {test_accuracy:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "L9oVaRo-dGYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_test_images(test_data_path):\n",
        "    test_images = []\n",
        "    test_labels = []\n",
        "    file_names = [f for f in os.listdir(test_data_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
        "\n",
        "    for file_name in file_names:\n",
        "        image_path = os.path.join(test_data_path, file_name)\n",
        "        if not os.path.isfile(image_path):\n",
        "            continue\n",
        "\n",
        "        img_processed = preprocess_image(image_path)\n",
        "        fourier_feature = compute_fourier_features(image_path)\n",
        "\n",
        "        if img_processed is not None and fourier_feature is not None:\n",
        "            test_images.append((img_processed, fourier_feature.reshape(1, 50176)))\n",
        "            test_labels.append(0)  # Dummy label\n",
        "\n",
        "    return test_images, test_labels\n"
      ],
      "metadata": {
        "id": "EcTtoqHwdHsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "test_images, test_labels = load_test_images(test_data_path)\n",
        "\n",
        "# Convert test data to arrays\n",
        "test_x_images = np.vstack([img[0] for img in test_images]).astype(np.float32)\n",
        "test_x_fourier = np.vstack([img[1] for img in test_images]).astype(np.float32)\n",
        "test_x_fourier = test_x_fourier.reshape(len(test_x_fourier), 50176)  # Ensure correct shape\n",
        "test_y = np.array(test_labels)\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict([test_x_images, test_x_fourier])\n",
        "predicted_classes = (predictions >= 0.5).astype(int).flatten()\n",
        "\n",
        "# Compute metrics\n",
        "accuracy = accuracy_score(test_y, predicted_classes)\n",
        "precision = precision_score(test_y, predicted_classes, zero_division=1)\n",
        "recall = recall_score(test_y, predicted_classes, zero_division=1)\n",
        "f1 = f1_score(test_y, predicted_classes, zero_division=1)\n",
        "conf_matrix = confusion_matrix(test_y, predicted_classes)\n",
        "report = classification_report(test_y, predicted_classes)\n",
        "\n",
        "# Print results\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"Precision: {precision:.2f}\")\n",
        "print(f\"Recall: {recall:.2f}\")\n",
        "print(f\"F1 Score: {f1:.2f}\")\n",
        "print(\"Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(6, 5))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "LAE2vySAdJVf"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}